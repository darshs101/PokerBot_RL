# -*- coding: utf-8 -*-
"""Poker

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MqxzeC9qOsqUQ7X2i9LwiI0B0ngPSbbi
"""

!pip install pypokerengine
from pypokerengine.utils.card_utils import estimate_hole_card_win_rate
from pypokerengine.utils.card_utils import gen_cards
import random
import numpy as np
from pypokerengine.api.game import setup_config, start_poker
from pypokerengine.players import BasePokerPlayer
import tensorflow as tf
from keras import models
from keras import layers

initial_stack = 1000

class DQNModel(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.dense1 = layers.Dense(128, activation='relu')
        self.dense2 = layers.Dense(128, activation='relu')
        self.q_values = layers.Dense(3)  # Q-values for fold, call, raise
        self.raise_amount = layers.Dense(1)  # predicted raise amount

    def call(self, state_input):
        x = self.dense1(state_input)
        x = self.dense2(x)
        q_vals = self.q_values(x)
        raise_amt = self.raise_amount(x)
        return q_vals, raise_amt

class PokerPlayer(BasePokerPlayer):
    def __init__(self,name):
        super().__init__()
        self.model = DQNModel()
        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        self.name = name
        self.exploration = 0.5
        self.initial_stack = initial_stack
        self.stack = initial_stack

    def get_state_representation(self, hole_card, round_state):
        community_card = round_state.get("community_card", [])

        # convert string cards to card objects to make them valid parameters
        hole_card_converted = gen_cards(hole_card)
        community_card_converted = gen_cards(community_card)

        # win rate calculated with the hole cards and revealed community cards
        win_rate = estimate_hole_card_win_rate(
        nb_simulation=100,
        nb_player=6,
        hole_card=hole_card_converted,
        community_card=community_card_converted)
        print("win rate: ", win_rate)
        street_map = {'preflop': 0, 'flop': 1, 'turn': 2, 'river': 3, 'showdown':4}

        return win_rate, street_map[round_state['street']], round_state['pot']['main']['amount']

    def declare_action(self, valid_actions, hole_card, round_state):

        # normalization and whatnot
        win_rate, street_num, raw_potsize, = self.get_state_representation(hole_card, round_state)
        street = np.zeros(5)
        street[street_num] = 1
        potsize = raw_potsize/3000
        call_amount = valid_actions[1]['amount']/2000

        input_vector = []

        input_vector.append(win_rate)
        input_vector.extend(street)
        input_vector.append(potsize)
        input_vector.append(call_amount)
        state_input = tf.convert_to_tensor([input_vector], dtype=tf.float32)

        # exploration vs Exploitation policy
        if random.random() < self.exploration:

            action_str = random.choice([a['action'] for a in valid_actions])
            if action_str == 'raise':
              raise_range = [a for a in valid_actions if a['action'] == 'raise'][0]['amount']
              amount = random.randint(raise_range['min'], raise_range['max'])
              if amount<0:
                action_str = 'fold'
                amount = 0
            elif action_str == 'call':
              amount = valid_actions[1]['amount']
            else:
              amount = 0
        else:
            q_values, raise_out = self.model(state_input)
            action_idx = tf.argmax(q_values[0]).numpy()
            action_str = ['fold', 'call', 'raise'][action_idx]
            if action_str == 'raise':
              amount = int(tf.clip_by_value(raise_out[0][0], valid_actions[2]['amount']['min'], valid_actions[2]['amount']['max']).numpy())
              if amount<0:
                action_str = 'fold'
                amount = 0

            else:
              amount = valid_actions[action_idx]['amount']

        self.episode_memory.append((state_input, action_str, amount));
        self.hole_card = hole_card

        print("cards:",hole_card)
        return action_str, amount

    def receive_game_update_message(self, action, round_state):
      if round_state["street"] == "preflop":
        if self.player_pos is None:
            print("ERROR: Player position not set!")
            return

        player_data = round_state["seats"][self.player_pos]


    def receive_round_result_message(self, winners, hand_info, round_state):
      self.exploration *= 0.995


      self.stack = round_state['seats'][self.player_pos]['stack']
      change = self.stack - self.initial_stack

      # Scaled reward suggestion (optional)
      reward_scale = 500
      reward = np.tanh(change / reward_scale)

      self.initial_stack = self.stack

      for state_input, action_str, amount in self.episode_memory:
          with tf.GradientTape() as tape:
              q_vals, raise_out = self.model(state_input)
              target_q = q_vals.numpy()
              idx = ['fold', 'call', 'raise'].index(action_str)

              target_q[0][idx] = reward  # naive Q-learning target

              loss = tf.reduce_mean(tf.square(q_vals - target_q))

              if action_str == 'raise':
                  predicted_amt = raise_out[0][0]
                  loss += tf.square(predicted_amt - amount) * 0.01

          grads = tape.gradient(loss, self.model.trainable_variables)
          self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))
      self.episode_memory = []


    def receive_game_start_message(self, game_info):
      self.player_pos = next(
          (i for i, seat in enumerate(game_info['seats']) if seat['uuid'] == self.uuid),
        None )

    def receive_round_start_message(self, round_count, hole_card, seats):
      self.hole_card = hole_card
      self.episode_memory = []

    def receive_street_start_message(self, street, round_state):
        pass

agents = []
for x in range(6):
  agents.append(PokerPlayer(name=f"agent_{x}"))

for game_num in range(100):
    print(f"\n=== Game {game_num + 1} ===")

    config = setup_config(max_round=10, initial_stack=initial_stack, small_blind_amount=20)

    for agent in agents:
        config.register_player(name=agent.name, algorithm=agent)

    game_result = start_poker(config, verbose=1)

print(agents[0].exploration)